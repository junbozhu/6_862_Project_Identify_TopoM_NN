# pytorch neural network ReLU CrossEntropyLoss Adam:
#  unit=[40],batch=64,lr=1e-03,betas=(0.9, 0.999),eps=1e-08,decay=0.0,amsgrad=False,epoch=64
# train_loss, train_acc, val_loss, val_acc
0.71034662 0.42170619 0.70891628 0.42615819
0.44347643 0.77184361 0.38182639 0.82418128
0.37294842 0.82856847 0.36949430 0.82981243
0.36316857 0.83300530 0.36401664 0.83264646
0.35819376 0.83553451 0.36067834 0.83439398
0.35564394 0.83828378 0.35724328 0.83680073
0.35026600 0.84032093 0.35605246 0.84014196
0.34633383 0.84266022 0.35303943 0.84033542
0.34317526 0.84484407 0.35101204 0.84254852
0.33918804 0.84821054 0.34870814 0.84448916
0.33527921 0.85078721 0.34580998 0.84557693
0.33204290 0.85345017 0.34354056 0.84744037
0.32878246 0.85603111 0.34188216 0.84798402
0.32506343 0.85782654 0.33914151 0.84973128
0.32132096 0.86020898 0.33844287 0.85070214
0.31676137 0.86240582 0.33612202 0.85155672
0.31316178 0.86448180 0.33323037 0.85233312
0.31109328 0.86597516 0.33242105 0.85377000
0.30716342 0.86752461 0.33156802 0.85477968
0.30410334 0.86948836 0.32938389 0.85594518
0.30081054 0.87127951 0.32982455 0.85609955
0.29773578 0.87280740 0.32847935 0.85676039
0.29522964 0.87384754 0.32905448 0.85625583
0.29271848 0.87559124 0.32632808 0.85773109
0.29048115 0.87652347 0.32696411 0.85730470
0.28841176 0.87789601 0.32543072 0.85761426
0.28713099 0.87891887 0.32575016 0.85924542
0.28511965 0.87981227 0.32455182 0.85827547
0.28313962 0.88098626 0.32594484 0.85862465
0.28110532 0.88198755 0.32475544 0.85850784
0.27902009 0.88270398 0.32469878 0.85792499
0.27708534 0.88369669 0.32446261 0.85920604
0.27560571 0.88465483 0.32376372 0.85874038
0.27440349 0.88549217 0.32370793 0.86107039
0.27252760 0.88600144 0.32366193 0.85932359
0.27145171 0.88704596 0.32319406 0.86227355
0.26992555 0.88803430 0.32412772 0.86006054
0.26861080 0.88821121 0.32328881 0.86238991
0.26656841 0.88916075 0.32360451 0.86056493
0.26634800 0.89001102 0.32352990 0.86207991
0.26495412 0.89051166 0.32351248 0.86138159
0.26316666 0.89067137 0.32377327 0.86122496
0.26221613 0.89153026 0.32295114 0.86149734
0.26065333 0.89210864 0.32488566 0.86110805
0.25939609 0.89260058 0.32272518 0.86293348
0.25898633 0.89360194 0.32451793 0.86141996
0.25782677 0.89349400 0.32309672 0.86320532
0.25671585 0.89448673 0.32368934 0.86192380
0.25644114 0.89486650 0.32528224 0.86293375
0.25441031 0.89544489 0.32369627 0.86196244
0.25382292 0.89669220 0.32428216 0.86204171
0.25281539 0.89639004 0.32346128 0.86340040
0.25174412 0.89725761 0.32540548 0.86576815
0.25070904 0.89746046 0.32457378 0.86355451
0.24923633 0.89787480 0.32490677 0.86305075
0.24850426 0.89817260 0.32393363 0.86273992
0.24809740 0.89901853 0.32566199 0.86200135
0.24709327 0.89890197 0.32514916 0.86262348
0.24632772 0.89930774 0.32583375 0.86328295
0.24581553 0.90011913 0.32641378 0.86215708
0.24457371 0.90003715 0.32523971 0.86297294
0.24423748 0.90083557 0.32484853 0.86262301
0.24282387 0.90118513 0.32648781 0.86184671
0.24198031 0.90130602 0.32705416 0.86200154
0.24116244 0.90192754 0.32642224 0.86378851
