# pytorch neural network ReLU CrossEntropyLoss Adam:
#  unit=[80],batch=64,lr=1e-03,betas=(0.9, 0.999),eps=1e-08,decay=0.0,amsgrad=False,epoch=64
# train_loss, train_acc, val_loss, val_acc
0.03006439 0.13517747 0.02980649 0.13443559
0.00865787 0.00873170 0.01311149 0.00608166
0.00407723 0.00211636 0.01471838 0.00543821
0.00494056 0.00235607 0.01421369 0.00659366
0.00451761 0.00299224 0.01405278 0.00682861
0.00446726 0.00320031 0.01377288 0.00590345
0.00586420 0.00370777 0.01504914 0.00709184
0.00568604 0.00317073 0.01474664 0.00772711
0.00577171 0.00286387 0.01454544 0.00714194
0.00622299 0.00315449 0.01516273 0.00815924
0.00602747 0.00314011 0.01395293 0.00767502
0.00556695 0.00253696 0.01410698 0.00744854
0.00537062 0.00289655 0.01477260 0.00752073
0.00561622 0.00304658 0.01422354 0.00730426
0.00502284 0.00293090 0.01471064 0.00624746
0.00476655 0.00237759 0.01371827 0.00659491
0.00601358 0.00197896 0.01457048 0.00614471
0.00507820 0.00182703 0.01370169 0.00486390
0.00432775 0.00179122 0.01441981 0.00585638
0.00586130 0.00188904 0.01396416 0.00716682
0.00379926 0.00197244 0.01476317 0.00600399
0.00312912 0.00130108 0.01375651 0.00478003
0.00282962 0.00136481 0.01529407 0.00628476
0.00251277 0.00125428 0.01309033 0.00479220
0.00256370 0.00135783 0.01364711 0.00643261
0.00214994 0.00090356 0.01367803 0.00618522
0.00228269 0.00092483 0.01326465 0.00785267
0.00162912 0.00166941 0.01081922 0.00547574
0.00211032 0.00145515 0.01314620 0.00516002
0.00205709 0.00146012 0.01332572 0.00486119
0.00228281 0.00134170 0.01385557 0.00554508
0.00165240 0.00168579 0.01284367 0.00593368
0.00291201 0.00148281 0.01295522 0.00536787
0.00180853 0.00151852 0.01222151 0.00524414
0.00174132 0.00180392 0.01236480 0.00446728
0.00220288 0.00164632 0.01208747 0.00433314
0.00199007 0.00149463 0.01426052 0.00427861
0.00175301 0.00164430 0.01209913 0.00420062
0.00307954 0.00175353 0.01450859 0.00489904
0.00224827 0.00172258 0.01442804 0.00520536
0.00249140 0.00162174 0.01347377 0.00404305
0.00208917 0.00159060 0.01326090 0.00587810
0.00145423 0.00156518 0.01312990 0.00635046
0.00239800 0.00184199 0.01374508 0.00317629
0.00299251 0.00198542 0.01557433 0.00532152
0.00224173 0.00173958 0.01409803 0.00552679
0.00189311 0.00158971 0.01366429 0.00691907
0.00539937 0.00174840 0.01513638 0.00608446
0.00408286 0.00253912 0.01400337 0.00639118
0.00350574 0.00212225 0.01522586 0.00538678
0.00288816 0.00131542 0.01460175 0.00454795
0.00237725 0.00156240 0.01363917 0.00651073
0.00250736 0.00192043 0.01457415 0.00419199
0.00319362 0.00182165 0.01422371 0.00631909
0.00289749 0.00169886 0.01539857 0.00472499
0.00316024 0.00182369 0.01466873 0.00435376
0.00326989 0.00227329 0.01474218 0.00655939
0.00265800 0.00167618 0.01426860 0.00619585
0.00497879 0.00167156 0.01190821 0.00575209
0.00358041 0.00208391 0.01428158 0.00581243
0.00246734 0.00177545 0.01516921 0.00641910
0.00235987 0.00149809 0.01534264 0.00516678
0.00281493 0.00132844 0.01708223 0.00405385
0.00270104 0.00152742 0.01471514 0.00569400
0.00270629 0.00135649 0.01585942 0.00522900
