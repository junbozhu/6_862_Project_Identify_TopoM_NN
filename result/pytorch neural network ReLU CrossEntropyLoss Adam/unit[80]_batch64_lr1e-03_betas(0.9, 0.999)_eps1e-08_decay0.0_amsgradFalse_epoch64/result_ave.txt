# pytorch neural network ReLU CrossEntropyLoss Adam:
#  unit=[80],batch=64,lr=1e-03,betas=(0.9, 0.999),eps=1e-08,decay=0.0,amsgrad=False,epoch=64
# train_loss, train_acc, val_loss, val_acc
0.69528982 0.50621392 0.69601868 0.50102321
0.42871499 0.78431235 0.37861999 0.82456929
0.36952284 0.82967772 0.36699342 0.83086066
0.36099679 0.83393328 0.36087374 0.83497648
0.35396688 0.83765796 0.35698842 0.83707275
0.34922277 0.84084322 0.35496563 0.83831507
0.34525125 0.84417947 0.35168450 0.84379184
0.33986776 0.84759343 0.34781328 0.84487825
0.33521549 0.85098580 0.34491161 0.84631506
0.33043214 0.85364441 0.34081833 0.84930499
0.32531983 0.85673040 0.33828567 0.84977129
0.32051303 0.85971707 0.33614808 0.85248876
0.31574567 0.86220741 0.33324396 0.85314870
0.31092418 0.86558253 0.33063011 0.85547807
0.30635784 0.86789162 0.32947284 0.85544044
0.30167073 0.87079626 0.32691587 0.85819610
0.29912875 0.87316573 0.32626079 0.85780755
0.29416561 0.87548771 0.32573784 0.85679768
0.29061067 0.87798241 0.32230889 0.86005973
0.28793487 0.87979510 0.32200651 0.86130260
0.28331196 0.88100789 0.32025428 0.86215808
0.27966855 0.88299756 0.31970283 0.86103076
0.27637592 0.88503471 0.31859512 0.86250664
0.27301602 0.88635541 0.31863887 0.86087521
0.27070260 0.88794367 0.31834191 0.86363325
0.26779827 0.88903561 0.31728657 0.86390516
0.26510989 0.89049875 0.31613263 0.86596298
0.26207330 0.89213455 0.31961100 0.86386570
0.26013227 0.89304950 0.31675879 0.86499329
0.25765984 0.89473706 0.31709494 0.86499148
0.25553186 0.89522907 0.31706734 0.86483566
0.25249640 0.89694252 0.31786212 0.86623481
0.25105453 0.89822866 0.31734531 0.86743949
0.24820351 0.89900126 0.31829025 0.86724556
0.24594818 0.90042557 0.31748740 0.86701093
0.24442306 0.90092620 0.31886144 0.86635126
0.24215816 0.90200518 0.31913747 0.86623399
0.24069679 0.90275617 0.31820873 0.86794388
0.23947657 0.90400346 0.31947001 0.86809688
0.23673088 0.90472861 0.31862609 0.86697294
0.23494666 0.90578600 0.31970380 0.86868073
0.23343088 0.90671831 0.31810038 0.86879683
0.23118023 0.90709372 0.31838042 0.86751723
0.22986889 0.90810372 0.31810567 0.86941931
0.22841506 0.90894102 0.32000129 0.86813797
0.22681967 0.90951933 0.32013042 0.86918556
0.22561572 0.91077963 0.32063577 0.86879801
0.22569987 0.91095660 0.32117158 0.86903012
0.22361798 0.91164281 0.32094682 0.86895446
0.22099786 0.91216938 0.32049786 0.86918430
0.21895903 0.91316638 0.32257825 0.86638990
0.21743143 0.91355915 0.32131986 0.87074062
0.21606821 0.91446115 0.32102165 0.87011797
0.21535024 0.91507404 0.32346651 0.87178723
0.21392971 0.91579912 0.32529934 0.86825481
0.21198473 0.91648108 0.32269490 0.86953576
0.21146365 0.91630845 0.32384245 0.87058335
0.20986472 0.91781037 0.32557659 0.86852663
0.20882970 0.91815136 0.33040692 0.86809815
0.20800824 0.91801324 0.32720671 0.86875845
0.20600849 0.91932963 0.32724766 0.87050663
0.20488927 0.91942028 0.32804229 0.86972832
0.20403469 0.92009785 0.32873548 0.87019570
0.20316613 0.92019282 0.32924971 0.86906874
0.20112226 0.92143149 0.32977367 0.87062317
