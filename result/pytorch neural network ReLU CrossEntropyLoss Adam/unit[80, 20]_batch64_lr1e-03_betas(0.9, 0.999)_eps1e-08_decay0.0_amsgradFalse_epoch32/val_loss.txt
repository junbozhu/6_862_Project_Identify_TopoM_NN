# pytorch neural network ReLU CrossEntropyLoss Adam:
#  unit=[80, 20],batch=64,lr=1e-03,betas=(0.9, 0.999),eps=1e-08,decay=0.0,amsgrad=False,epoch=32
0.73158872 0.77512968 0.67275212 0.71741247 0.72384070 0.69686597 0.69508835 0.72060676 0.64575020 0.63184876
0.36946014 0.37190373 0.34424369 0.36936557 0.36579926 0.37027628 0.38438286 0.35485232 0.39097265 0.38947357
0.35912656 0.35936219 0.33987383 0.35965086 0.35837349 0.35775283 0.37646804 0.34261813 0.37884304 0.37918597
0.35297616 0.35299245 0.32961678 0.35448842 0.35776962 0.35044814 0.37366491 0.33511503 0.37499660 0.37364406
0.34668836 0.35257054 0.32792551 0.35168951 0.35242937 0.34602983 0.37009382 0.33310307 0.36888227 0.36729123
0.34288606 0.34655794 0.31812470 0.34888445 0.34584496 0.33904542 0.36255714 0.33005145 0.36147108 0.35945490
0.34116234 0.33932434 0.31483556 0.34254284 0.33901531 0.33439916 0.35772505 0.32057679 0.36267916 0.35120489
0.33686943 0.33469144 0.31102471 0.34066380 0.33678902 0.32914576 0.35332217 0.32476896 0.35563776 0.34531961
0.33487428 0.33200727 0.31374423 0.33778344 0.33738178 0.32587679 0.35403568 0.31392049 0.35471544 0.35405686
0.33688036 0.33012796 0.31120118 0.33592403 0.33813848 0.32185012 0.35218587 0.31118359 0.34843151 0.34198292
0.32892847 0.32946996 0.30630756 0.33082633 0.32334559 0.32020259 0.34494042 0.30747586 0.35552107 0.33692638
0.32800017 0.32820384 0.31286882 0.33713787 0.32312686 0.31550502 0.33821299 0.30549188 0.34275075 0.34254868
0.32751353 0.32295565 0.32302603 0.32374936 0.32234870 0.30922600 0.34105530 0.31033112 0.34435484 0.32808061
0.32828116 0.32234196 0.31698483 0.32956574 0.32309790 0.31112240 0.34015368 0.30016283 0.34059416 0.32815005
0.33565739 0.32259438 0.30072911 0.33216063 0.31866561 0.31227547 0.33544656 0.29744641 0.34133327 0.32296932
0.32702014 0.32055539 0.30176626 0.32277396 0.31563980 0.30889216 0.33613311 0.31388413 0.34073660 0.32648035
0.32924514 0.31879623 0.29894468 0.32264916 0.31780986 0.31163917 0.33784769 0.29896973 0.34561767 0.34202884
0.32772155 0.32480002 0.30275683 0.32836418 0.31102745 0.31212403 0.33061279 0.29573463 0.34966891 0.32957694
0.32532939 0.32952891 0.29561024 0.31928670 0.30700728 0.31551323 0.33046783 0.30084592 0.33977812 0.32637334
0.32679821 0.32351674 0.29438052 0.32324824 0.32549732 0.30762769 0.33457409 0.30716369 0.34347959 0.33846866
0.32199376 0.32534080 0.29808860 0.31912737 0.32833892 0.30953633 0.33070271 0.30171308 0.33734961 0.32501546
0.33817065 0.33520078 0.30412932 0.32507728 0.31094486 0.30694899 0.33385112 0.30099720 0.34865214 0.32412438
0.32306082 0.32998779 0.30225950 0.32397201 0.32023411 0.31076711 0.33686729 0.30105546 0.34652426 0.32468897
0.32396769 0.32657069 0.30185245 0.31629874 0.32265324 0.31288254 0.33742141 0.30005808 0.35087876 0.32656169
0.32698966 0.32449630 0.30300983 0.32855464 0.31347306 0.31712432 0.33027864 0.30790799 0.33736349 0.33458785
0.32173167 0.32611078 0.31628961 0.31343030 0.31919773 0.31137485 0.33635801 0.30002614 0.34589299 0.34602421
0.32667400 0.33220824 0.30302181 0.32770654 0.32269965 0.31153630 0.33502730 0.31744690 0.34839275 0.33434642
0.33777948 0.34646388 0.30186734 0.32334397 0.31837344 0.33023147 0.33779381 0.31378727 0.34639775 0.36410025
0.33312855 0.33468631 0.31525925 0.31973931 0.33652538 0.32014921 0.35289516 0.31179321 0.37031768 0.34739020
0.33362547 0.33978928 0.30582010 0.33232876 0.34113658 0.32305187 0.34801442 0.31388107 0.36785712 0.34097625
0.33631786 0.34072821 0.31175607 0.33197048 0.32257514 0.32593332 0.34581996 0.31506500 0.36478412 0.34248266
0.33398808 0.34009962 0.32962594 0.33599060 0.32455716 0.32675562 0.36555908 0.32319702 0.36567263 0.34628277
0.33595240 0.34881815 0.31174016 0.33338840 0.33499108 0.32272410 0.35759811 0.32757218 0.35536740 0.34901515
