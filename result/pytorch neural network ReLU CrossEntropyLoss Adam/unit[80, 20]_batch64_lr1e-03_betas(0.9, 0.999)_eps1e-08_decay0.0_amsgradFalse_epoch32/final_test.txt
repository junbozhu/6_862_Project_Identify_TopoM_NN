# pytorch neural network ReLU CrossEntropyLoss Adam:
#  unit=[80, 20],batch=64,lr=1e-03,betas=(0.9, 0.999),eps=1e-08,decay=0.0,amsgrad=False,epoch=32
#  training loss,	 training accuracy,	 test loss,	 test accuracy
0.70605207 0.43142357 0.70606948 0.42762238
0.42384145 0.79145467 0.34501633 0.84545457
0.36246758 0.83165663 0.33254350 0.84895104
0.35297966 0.83752185 0.32581095 0.85174823
0.34574260 0.84261024 0.32060038 0.85279721
0.33891236 0.84800935 0.31625908 0.85629368
0.33164903 0.85305887 0.31324094 0.85664338
0.32440271 0.85760343 0.30964172 0.86013985
0.31730148 0.86148769 0.30743402 0.86328673
0.31046879 0.86560500 0.30605569 0.86748254
0.30391775 0.86890656 0.30497496 0.87272727
0.29758556 0.87220818 0.30318853 0.87412590
0.29139833 0.87613130 0.30234908 0.87447554
0.28549158 0.87865603 0.30055184 0.87377620
0.27954941 0.88215190 0.30080319 0.87202799
0.27390952 0.88490969 0.30120335 0.87132865
0.26823933 0.88739562 0.30215553 0.87097901
0.26282336 0.88960963 0.30228165 0.86853147
0.25760366 0.89260048 0.30283874 0.86923075
0.25247412 0.89551371 0.30475505 0.87132865
0.24772115 0.89827150 0.30503975 0.87027973
