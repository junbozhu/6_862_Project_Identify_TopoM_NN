# pytorch neural network ReLU CrossEntropyLoss Adam:
#  unit=[80, 20],batch=64,lr=1e-03,betas=(0.9, 0.999),eps=1e-08,decay=0.0,amsgrad=False,epoch=32
0.29503107 0.28299689 0.69720495 0.35170808 0.29503107 0.47709626 0.47127330 0.30201864 0.71156830 0.70972764
0.83113354 0.82880437 0.84316772 0.83618015 0.83423913 0.82919252 0.81521738 0.82880437 0.82181674 0.82490271
0.83152175 0.83346272 0.84355593 0.84083849 0.83812112 0.83812112 0.82104039 0.83385092 0.82802796 0.82607001
0.83618015 0.83695650 0.85248446 0.84161490 0.84200311 0.83773291 0.82725155 0.84083849 0.82996893 0.83151752
0.84316772 0.84122670 0.85131985 0.84743786 0.84200311 0.84006214 0.82802796 0.84743786 0.83152175 0.83968872
0.84899068 0.84316772 0.85830748 0.84472048 0.84277952 0.84588510 0.83190995 0.85054350 0.83618015 0.84163421
0.85170805 0.84821427 0.86335403 0.84782606 0.84899068 0.84704971 0.84239131 0.86141306 0.84277952 0.84747082
0.85520184 0.84083849 0.86568326 0.85481364 0.84937888 0.85364908 0.84006214 0.85054350 0.84161490 0.84980547
0.85753107 0.85054350 0.86529505 0.85287267 0.85131985 0.85209626 0.84472048 0.85636646 0.84083849 0.85252917
0.85287267 0.84433228 0.86529505 0.85326087 0.85209626 0.85636646 0.84704971 0.85869563 0.84976709 0.85330737
0.85791928 0.85054350 0.86490685 0.85675466 0.85714287 0.85442549 0.84899068 0.86218941 0.84239131 0.85680932
0.85947204 0.85248446 0.86413044 0.84704971 0.85753107 0.86607140 0.85714287 0.86024845 0.85131985 0.85914397
0.86180127 0.85675466 0.86451864 0.86335403 0.85869563 0.86956519 0.84976709 0.86257762 0.85093170 0.86420232
0.86218941 0.85520184 0.87267083 0.85947204 0.86607140 0.86529505 0.84549689 0.86645961 0.85559005 0.86108947
0.86024845 0.86335403 0.87072980 0.85908383 0.86180127 0.86762422 0.85170805 0.86529505 0.85209626 0.86887157
0.86801243 0.85791928 0.87305903 0.86296582 0.85869563 0.86645961 0.85559005 0.85869563 0.85248446 0.86653697
0.86413044 0.85597825 0.87189442 0.86490685 0.86257762 0.87267083 0.85131985 0.87150621 0.85442549 0.85953307
0.86568326 0.86218941 0.87072980 0.86218941 0.86762422 0.86762422 0.85908383 0.87072980 0.85054350 0.86186773
0.87150621 0.85364908 0.87927020 0.87228262 0.87034160 0.86762422 0.86490685 0.86878884 0.85520184 0.86926073
0.86723602 0.86490685 0.87888199 0.87305903 0.86645961 0.86645961 0.85986024 0.86607140 0.85170805 0.87198442
0.86956519 0.85714287 0.87732917 0.87267083 0.86413044 0.87034160 0.86490685 0.87538821 0.85986024 0.86731517
0.86296582 0.85636646 0.88198757 0.86995339 0.86956519 0.87111801 0.86490685 0.87189442 0.86374223 0.87392998
0.87034160 0.85908383 0.87888199 0.87461179 0.86840063 0.87305903 0.86451864 0.87072980 0.85636646 0.87003893
0.87228262 0.86218941 0.87732917 0.87577641 0.86607140 0.87461179 0.85869563 0.87577641 0.85830748 0.86887157
0.87461179 0.86141306 0.87577641 0.87694097 0.86568326 0.87072980 0.86568326 0.87538821 0.86490685 0.86848247
0.87267083 0.86141306 0.87538821 0.88043481 0.87189442 0.87771738 0.86102486 0.87732917 0.86024845 0.86303502
0.87344718 0.86257762 0.87888199 0.87732917 0.86956519 0.87344718 0.86995339 0.86956519 0.86218941 0.87237352
0.86723602 0.84782606 0.87927020 0.87810558 0.86995339 0.87305903 0.86490685 0.86568326 0.86024845 0.85914397
0.87461179 0.85869563 0.87500000 0.88121116 0.86568326 0.87461179 0.85986024 0.87344718 0.85908383 0.86770427
0.87072980 0.85520184 0.88043481 0.87538821 0.86917704 0.87072980 0.86102486 0.87461179 0.85791928 0.87276262
0.87150621 0.86451864 0.88004661 0.87810558 0.87810558 0.87267083 0.86335403 0.87500000 0.86180127 0.87120622
0.87034160 0.86218941 0.87267083 0.87189442 0.87034160 0.86762422 0.85675466 0.87189442 0.85753107 0.86964983
0.87072980 0.85947204 0.87616462 0.87383538 0.87150621 0.87538821 0.86024845 0.86607140 0.86684781 0.86848247
