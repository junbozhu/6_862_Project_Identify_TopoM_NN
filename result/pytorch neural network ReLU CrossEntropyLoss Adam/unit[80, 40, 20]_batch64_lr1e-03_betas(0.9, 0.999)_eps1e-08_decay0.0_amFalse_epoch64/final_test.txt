# pytorch neural network ReLU CrossEntropyLoss Adam:
#  unit=[80, 40, 20],batch=64,lr=1e-03,betas=(0.9, 0.999),eps=1e-08,decay=0.0,amsgrad=False,epoch=64
#  training loss,	 training accuracy,	 test loss,	 test accuracy
0.70341326 0.28914353 0.70384936 0.27867132
0.40257311 0.80959409 0.33431507 0.84720278
0.35232539 0.83938628 0.32504775 0.85804194
0.33986776 0.84824240 0.31879992 0.86153847
0.32744514 0.85624391 0.31540566 0.86433566
0.31498371 0.86354631 0.30978612 0.86783218
0.30311392 0.87014955 0.30311187 0.87062937
0.29198825 0.87465525 0.30004241 0.87622380
0.28182070 0.88090891 0.29795270 0.87622380
0.27265400 0.88731796 0.29684950 0.87552446
0.26404925 0.89291126 0.29685669 0.87622380
0.25618201 0.89687318 0.29717582 0.87692308
0.24903195 0.90009713 0.29914272 0.87587410
0.24237247 0.90370947 0.30013312 0.87447554
0.23615918 0.90662265 0.30152697 0.87587410
0.23048651 0.90844822 0.30568229 0.87307692
0.22533439 0.91112840 0.30878478 0.87132865
0.22035082 0.91442996 0.31465014 0.87062937
0.21604659 0.91648865 0.31604047 0.87167829
