# pytorch neural network ReLU CrossEntropyLoss Adam:
#  unit=[80, 40, 20],batch=64,lr=1e-03,betas=(0.9, 0.999),eps=1e-08,decay=0.0,amsgrad=False,epoch=64
# train_loss, train_acc, val_loss, val_acc
0.69621338 0.45729239 0.69639180 0.45453897
0.43654963 0.78366074 0.37213744 0.82860711
0.36209892 0.83297517 0.35932029 0.83365759
0.35235118 0.83910817 0.35496164 0.83769566
0.34368567 0.84414921 0.34857507 0.84243278
0.33577905 0.84946229 0.34336983 0.84615940
0.32652808 0.85506874 0.34215615 0.84643178
0.31725506 0.86034289 0.33649391 0.85012147
0.30943841 0.86542723 0.33451760 0.85050886
0.30198634 0.86922531 0.33071777 0.85221783
0.29460330 0.87334703 0.32790049 0.85423665
0.28616317 0.87767597 0.32267366 0.86068220
0.27654163 0.88276022 0.32113396 0.86044838
0.26877406 0.88664467 0.32138691 0.86169115
0.26214923 0.88995067 0.31799548 0.86277875
0.25379847 0.89418893 0.31633790 0.86545787
0.24531611 0.89849631 0.31461576 0.86965112
0.23653829 0.90267422 0.31613468 0.86903065
0.23035542 0.90603210 0.31631557 0.86972932
0.22305344 0.90894108 0.32212995 0.86848772
0.21588204 0.91283410 0.32446627 0.86949649
0.21048751 0.91505255 0.32255635 0.87015652
0.20496955 0.91696447 0.32503108 0.86953459
0.19753642 0.92072808 0.32607334 0.87011688
0.19180656 0.92366294 0.33310364 0.87097156
0.18634822 0.92542821 0.33629945 0.87066072
0.18241466 0.92699056 0.34146054 0.87349475
0.18071308 0.92792286 0.34398051 0.87163241
0.17242023 0.93108645 0.34913095 0.87299010
0.16628298 0.93390484 0.35208841 0.87318429
0.16357421 0.93508739 0.36403723 0.86934058
0.15990533 0.93719358 0.36394851 0.87411768
0.15529475 0.93873442 0.36739249 0.87291355
0.15214557 0.93969690 0.37678803 0.87038871
0.14850954 0.94123341 0.38368147 0.87298874
0.14684595 0.94176426 0.38806522 0.87104874
0.14075578 0.94483294 0.38419127 0.87357276
0.13833423 0.94582134 0.39480313 0.87225198
0.13605467 0.94596371 0.39800668 0.87143630
0.13240917 0.94770311 0.41029541 0.87264171
0.12860213 0.94960641 0.42016763 0.86964977
0.12699148 0.94999058 0.42897610 0.87143749
0.12541211 0.95049979 0.43230280 0.87174768
0.12138940 0.95236437 0.44444112 0.86759295
0.11944606 0.95314121 0.44246691 0.87287463
0.11897489 0.95343040 0.46103406 0.87128156
0.11665484 0.95413387 0.45480039 0.87034999
0.11161844 0.95649483 0.46710826 0.87003852
0.11043755 0.95749611 0.47812693 0.87104784
0.10958917 0.95729754 0.48850794 0.86949549
0.10755635 0.95783702 0.48435746 0.87136021
0.10232171 0.95973608 0.49485295 0.86883555
0.10217519 0.96027991 0.50128133 0.87167022
0.10356396 0.95988283 0.51688746 0.86751532
0.10237505 0.96055180 0.50730714 0.87058218
0.09844268 0.96181209 0.52464176 0.86992287
0.09476229 0.96330977 0.53659407 0.86891464
0.09378997 0.96340899 0.52715814 0.86766906
0.09407169 0.96336153 0.53651382 0.86980541
0.09131396 0.96457863 0.55032508 0.86871827
0.09064963 0.96484619 0.55931277 0.86992242
0.08781551 0.96620144 0.56304791 0.87069846
0.08955714 0.96542027 0.57008732 0.86778560
0.08992669 0.96587769 0.58248596 0.86809707
0.08813832 0.96577840 0.58373553 0.86906784
