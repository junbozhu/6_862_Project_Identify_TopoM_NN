# pytorch linear classifier ReLU CrossEntropyLoss SGD:
#  batch=64,lr=1e-02,momentum=0.9,epoch=32
0.60093170 0.42818323 0.51513976 0.47864908 0.37500000 0.36995342 0.55978262 0.47088510 0.39479813 0.30933851
0.81327641 0.81017083 0.81754661 0.81133538 0.80745339 0.81133538 0.79930127 0.80434781 0.81017083 0.79571986
0.81599379 0.81366462 0.82220495 0.81638199 0.81560558 0.81715840 0.81094718 0.81250000 0.81444097 0.80856031
0.82453418 0.81405282 0.82686335 0.82181674 0.82026398 0.82336956 0.80978262 0.81560558 0.81560558 0.80972761
0.82142860 0.81444097 0.82336956 0.82608694 0.82259315 0.82298136 0.81133538 0.81909937 0.81521738 0.81322956
0.82375777 0.81444097 0.82453418 0.82841617 0.82298136 0.82414597 0.81521738 0.82065219 0.81521738 0.81556422
0.82453418 0.81909937 0.82841617 0.82647514 0.82298136 0.82531059 0.81327641 0.82142860 0.81638199 0.81517512
0.82686335 0.82065219 0.82919252 0.82647514 0.82453418 0.82841617 0.81444097 0.82104039 0.81677020 0.81595331
0.82336956 0.82453418 0.82996893 0.82686335 0.82608694 0.82919252 0.81521738 0.82142860 0.81521738 0.81867707
0.82104039 0.82220495 0.82802796 0.82802796 0.82608694 0.82686335 0.81677020 0.82336956 0.81832296 0.81673151
0.82841617 0.82259315 0.82958072 0.82841617 0.82725155 0.82996893 0.81715840 0.82492238 0.81638199 0.81945527
0.82414597 0.82298136 0.82996893 0.82802796 0.82531059 0.82841617 0.81133538 0.82375777 0.81871116 0.82062256
0.82725155 0.82492238 0.83113354 0.82958072 0.82763976 0.83113354 0.81599379 0.82763976 0.81987578 0.82062256
0.82686335 0.82453418 0.83074534 0.83268636 0.82414597 0.82958072 0.81638199 0.82725155 0.82065219 0.82101166
0.82569873 0.82647514 0.82996893 0.83152175 0.82569873 0.83190995 0.81715840 0.82453418 0.81638199 0.82178986
0.82414597 0.82531059 0.83152175 0.83307451 0.82531059 0.83268636 0.81677020 0.82531059 0.81444097 0.82023346
0.82492238 0.82841617 0.83656830 0.83113354 0.82686335 0.83152175 0.81638199 0.82802796 0.81871116 0.82334632
0.82608694 0.82531059 0.83462733 0.83113354 0.82647514 0.83268636 0.81677020 0.82841617 0.81909937 0.82101166
0.82531059 0.82725155 0.83462733 0.83346272 0.82686335 0.83385092 0.81521738 0.82802796 0.81754661 0.82256812
0.82608694 0.82569873 0.83113354 0.82996893 0.82608694 0.83113354 0.81871116 0.82763976 0.81638199 0.82140076
0.82608694 0.82725155 0.82958072 0.83307451 0.82569873 0.83074534 0.81560558 0.82880437 0.81521738 0.82101166
0.82453418 0.82492238 0.82996893 0.83113354 0.82647514 0.83423913 0.81715840 0.82841617 0.81677020 0.82178986
0.82259315 0.82569873 0.83152175 0.83423913 0.82686335 0.83346272 0.81871116 0.83035713 0.81793481 0.82256812
0.82608694 0.82802796 0.83618015 0.83618015 0.82608694 0.83229816 0.81871116 0.83074534 0.81754661 0.82140076
0.82414597 0.82453418 0.83695650 0.83268636 0.82608694 0.83035713 0.81754661 0.82841617 0.81677020 0.82295722
0.82375777 0.82647514 0.83618015 0.83579195 0.82569873 0.83423913 0.81754661 0.83152175 0.81948757 0.82451361
0.82608694 0.82763976 0.83307451 0.83307451 0.82841617 0.83152175 0.81560558 0.83035713 0.82065219 0.82334632
0.82414597 0.83035713 0.83462733 0.83540374 0.82686335 0.83307451 0.81793481 0.83268636 0.81909937 0.82178986
0.82492238 0.83035713 0.83618015 0.83579195 0.82531059 0.83268636 0.81715840 0.82958072 0.81948757 0.82373542
0.82298136 0.82996893 0.83462733 0.83385092 0.82686335 0.83268636 0.81793481 0.82996893 0.81948757 0.82295722
0.82375777 0.82880437 0.83385092 0.83501554 0.82725155 0.82996893 0.81754661 0.83229816 0.81793481 0.82295722
0.82414597 0.83035713 0.83618015 0.83423913 0.82608694 0.83113354 0.81793481 0.82841617 0.81754661 0.82412452
0.82375777 0.82725155 0.83618015 0.83268636 0.82608694 0.82841617 0.81871116 0.82996893 0.81987578 0.82295722
