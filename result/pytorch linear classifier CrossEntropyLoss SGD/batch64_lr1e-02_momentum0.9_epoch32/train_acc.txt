# pytorch linear classifier ReLU CrossEntropyLoss SGD:
#  batch=64,lr=1e-02,momentum=0.9,epoch=32
0.59786785 0.42746773 0.52281064 0.48305926 0.40092364 0.36756009 0.57041734 0.48897234 0.39198929 0.30955771
0.77780658 0.77271354 0.77590746 0.77625275 0.77448314 0.76960593 0.77677071 0.77077127 0.76913118 0.77057171
0.81315553 0.81358713 0.81211966 0.81289655 0.81207651 0.81237859 0.81281024 0.81112695 0.81367344 0.81341964
0.81678104 0.81837803 0.81527042 0.81716949 0.81786007 0.81652206 0.81837803 0.81686735 0.81816220 0.81661272
0.81993181 0.81962967 0.81807590 0.81824851 0.81863695 0.81958652 0.81915492 0.81786007 0.81924123 0.81898600
0.82001811 0.82114029 0.81954336 0.81924123 0.81975919 0.81988865 0.81980234 0.82010442 0.82010442 0.82032365
0.82196039 0.82269412 0.82036340 0.82135612 0.82165825 0.82217616 0.82208985 0.82066554 0.82247829 0.82200646
0.82260782 0.82200354 0.82032025 0.82230568 0.82256466 0.82278043 0.82303941 0.82165825 0.82278043 0.82230854
0.82217616 0.82480901 0.82221937 0.82342786 0.82295310 0.82394576 0.82416159 0.82200354 0.82394576 0.82321465
0.82355732 0.82619017 0.82351416 0.82325524 0.82433426 0.82411844 0.82442057 0.82368684 0.82377315 0.82450914
0.82472271 0.82532692 0.82265097 0.82429105 0.82429105 0.82450688 0.82705337 0.82411844 0.82532692 0.82437974
0.82381630 0.82506800 0.82446373 0.82433426 0.82489532 0.82524061 0.82614702 0.82459319 0.82571542 0.82567424
0.82519746 0.82593119 0.82394576 0.82524061 0.82537013 0.82506800 0.82476586 0.82480901 0.82593119 0.82532901
0.82593119 0.82619017 0.82467955 0.82511115 0.82623333 0.82511115 0.82653546 0.82506800 0.82644916 0.82606256
0.82619017 0.82649231 0.82407528 0.82506800 0.82623333 0.82675129 0.82705337 0.82467955 0.82696706 0.82722759
0.82675129 0.82657862 0.82571542 0.82575858 0.82606071 0.82662177 0.82709652 0.82614702 0.82653546 0.82670981
0.82709652 0.82666492 0.82619017 0.82597435 0.82593119 0.82627648 0.82821876 0.82610387 0.82752818 0.82670981
0.82752818 0.82627648 0.82562906 0.82562906 0.82692391 0.82644916 0.82804608 0.82549959 0.82839137 0.82679611
0.82834822 0.82722604 0.82575858 0.82571542 0.82662177 0.82701021 0.82770079 0.82688075 0.82726920 0.82752967
0.82709652 0.82670808 0.82593119 0.82636279 0.82731235 0.82696706 0.82873666 0.82683760 0.82748502 0.82752967
0.82817560 0.82761449 0.82705337 0.82623333 0.82696706 0.82860720 0.82860720 0.82735550 0.82713974 0.82791799
0.82821876 0.82744181 0.82601750 0.82670808 0.82757133 0.82757133 0.82791662 0.82688075 0.82765764 0.82796115
0.82882297 0.82593119 0.82709652 0.82597435 0.82722604 0.82752818 0.82770079 0.82709652 0.82921147 0.82796115
0.82757133 0.82830507 0.82636279 0.82662177 0.82701021 0.82726920 0.82813239 0.82709652 0.82830507 0.82869470
0.82843453 0.82852089 0.82761449 0.82636279 0.82783031 0.82843453 0.82951355 0.82770079 0.82873666 0.82873785
0.82925463 0.82748502 0.82778710 0.82619017 0.82791662 0.82709652 0.82873666 0.82752818 0.82903880 0.82822007
0.82834822 0.82813239 0.82735550 0.82619017 0.82856405 0.82808924 0.82981569 0.82770079 0.82856405 0.82817692
0.82856405 0.82795978 0.82696706 0.82770079 0.82696706 0.82800293 0.82877982 0.82765764 0.82869351 0.82692558
0.82826191 0.82877982 0.82722604 0.82722604 0.82774395 0.82843453 0.82994521 0.82791662 0.82886618 0.82834953
0.82826191 0.82795978 0.82692391 0.82817560 0.82856405 0.82783031 0.82886618 0.82718289 0.82994521 0.82800430
0.82925463 0.82791662 0.82735550 0.82791662 0.82869351 0.82852089 0.82959992 0.82774395 0.82856405 0.82925564
0.82839137 0.82770079 0.82757133 0.82752818 0.82826191 0.82877982 0.82942724 0.82865036 0.82934093 0.82731390
0.82826191 0.82877982 0.82770079 0.82713974 0.82817560 0.82778710 0.82934093 0.82614702 0.82981569 0.82895362
