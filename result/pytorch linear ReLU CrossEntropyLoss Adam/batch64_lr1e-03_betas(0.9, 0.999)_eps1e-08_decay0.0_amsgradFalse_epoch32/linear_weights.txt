# pytorch linear ReLU CrossEntropyLoss Adam:
#  batch=64,lr=1e-03,betas=(0.9, 0.999),eps=1e-08,decay=0.0,amsgrad=False,epoch=32
#  trivial, non-trivial
0.28973344 -0.37096840
0.59453411 -0.43605520
-0.54168300 0.62732503
-0.65233837 0.65511425
-0.35432201 0.44146559
-0.01261943 -0.12052078
0.51965095 -0.59373500
0.80238047 -0.67327463
0.58078420 -0.72906610
0.19509824 -0.28660701
0.08115772 -0.04561985
0.01891921 0.07899589
-0.32338967 0.43465320
-0.06675585 0.24134201
0.28501785 -0.46858814
0.36751125 -0.49476940
0.61700330 -0.49059879
0.37658511 -0.39935153
0.90682590 -1.01192448
-0.15589133 0.10428797
-0.15467298 0.32250492
-0.58706981 0.64519225
-0.68704732 0.51358999
-0.59959713 0.49243184
-0.61802703 0.64286733
-0.63694469 0.77240527
-0.20818163 0.31038061
-0.28423366 0.19589527
-0.32015496 0.18658350
-0.07484444 0.16575627
0.08631387 0.06476798
0.03949450 0.07573904
0.25731169 -0.17736115
0.61321514 -0.49231572
0.91284712 -0.67370202
0.41359244 -0.47872430
1.05441875 -1.01639429
-0.04792055 -0.12225987
-0.25991011 0.05064935
-0.38955346 0.30806484
-0.50669564 0.24278893
-1.00722493 0.90580410
-0.24197210 0.14434201
0.28678044 -0.19939024
-0.04860042 0.03865892
-0.34309766 0.08151806
-0.12863101 -0.04530998
0.32938333 -0.03114554
0.21219820 -0.11638949
-0.15800980 0.19929869
-0.14330605 0.00467246
-0.22977840 -0.01891814
0.95975387 -0.86836969
0.57326685 -0.56652608
1.01812984 -0.99869084
0.08908881 -0.02784190
-0.23119661 -0.02775794
-0.46369047 0.39821699
-0.23477872 0.14747616
-0.28542083 0.29865680
0.09206849 -0.07095237
-0.19426011 0.17236746
0.03422659 -0.01037519
-0.72560330 0.77485522
-0.05321546 0.05901867
0.13094200 -0.10657601
0.02282061 -0.14437966
-0.07801576 0.20956661
0.11173709 -0.17732837
-0.64906457 0.49243205
0.24732175 -0.15570806
0.05856609 0.08653150
-0.32219912 0.37067945
-0.32626866 0.21117890
-0.52224571 0.31580714
0.01142750 -0.04410340
-0.22219472 0.42930261
-0.08772887 0.13021444
-0.09734578 0.12366950
0.18052647 -0.23228856
0.59496300 -0.45034183
0.09744113 -0.13447258
-0.88248329 0.88760087
0.03264456 -0.02283638
0.06778045 -0.05130753
-0.01882631 -0.00209837
0.04609733 -0.09703899
0.03140283 0.02090707
0.70135609 -0.38080294
-0.39988171 0.47169060
0.21966238 -0.34897348
-0.63552084 0.63797073
0.24095897 -0.06076825
-0.02327239 -0.10385852
-0.02891161 -0.00878361
0.05250549 -0.08251552
-0.07717774 -0.06413482
0.04054453 0.09436210
0.06296472 0.07325337
-0.17158051 -0.05494522
-0.15886473 -0.06470913
-0.03665666 0.00266900
-0.03687502 0.05459120
0.09626424 -0.14731272
0.10117189 -0.07041676
-0.12354305 -0.11742024
-0.04925076 0.10628295
0.02724422 -0.04077526
-0.00181316 -0.04720618
0.44973008 -0.55890183
-0.24117369 0.44099068
-0.38051677 0.38101476
-0.77238289 0.61538354
-0.62410718 0.75964065
-1.14676100 1.23832781
-0.90814331 0.69145714
-0.38859773 0.37805196
-0.29902894 0.34597638
-0.21248895 0.20710738
-0.09831474 0.21429179
-0.07363540 0.07139160
-0.34423771 0.12328993
0.03575217 0.09443064
0.07337702 -0.18657281
0.71521015 -0.61434420
0.93276791 -1.00903484
1.05018616 -0.82236473
-0.45435073 0.29538426
-0.49041610 0.34676174
0.27703559 -0.32103251
0.42691388 -0.48278192
0.29468299 -0.33743582
-0.02636954 0.13454752
-0.12875356 0.12753286
-0.31478056 0.36989754
-0.31014875 0.33920899
0.37913040 -0.37905716
0.14641313 -0.40207534
0.08254623 0.00631614
-0.10790255 -0.14066189
0.30605136 -0.29909279
-0.05840955 0.23789455
0.05247253 0.00816623
-0.22345596 0.31533607
0.46910204 -0.37734637
