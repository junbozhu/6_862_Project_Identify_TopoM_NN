# pytorch nn 3 hidden layer ReLU CrossEntropyLoss SGD:
#  unit=[80, 40, 20],batch=64,lr=1e-02,momentum0.9,epoch=32
0.68074400 0.68597831 0.70245087 0.69407235 0.71670264 0.70376061 0.70665545 0.71869313 0.67612317 0.69727624
0.39185099 0.37348494 0.37303008 0.39830602 0.37524289 0.37730633 0.39731420 0.36904095 0.40313377 0.40115667
0.38016549 0.36180005 0.34716163 0.36946232 0.36801188 0.36892542 0.39013348 0.34909310 0.38923865 0.38147824
0.37001280 0.35090079 0.34068805 0.36830943 0.35685866 0.35933453 0.38723334 0.33935150 0.37698214 0.37660187
0.36766585 0.37170946 0.49286591 0.36042665 0.35462253 0.35317267 0.37474237 0.33797905 0.37688538 0.36788201
0.36267462 0.34215730 0.34506814 0.35792604 0.35208749 0.35114778 0.37681713 0.33308326 0.37349703 0.36403421
0.35588657 0.34419348 0.33495934 0.35326788 0.36149536 0.35169545 0.37599271 0.32860802 0.37196599 0.36303533
0.35952511 0.33634199 0.33865294 0.35899181 0.34562665 0.34160702 0.38930431 0.33023348 0.36597740 0.35947063
0.37096755 0.33854252 0.33204186 0.34956123 0.34777167 0.34147746 0.36907551 0.32400876 0.36893015 0.35547587
0.35200283 0.33135914 0.32605515 0.35158597 0.34341760 0.34590394 0.36421215 0.38883357 0.36283110 0.35243158
0.34850154 0.33100348 0.32246464 0.35263089 0.34182297 0.33646759 0.36737786 0.32508134 0.37404633 0.35192643
0.34941399 0.33580976 0.31871209 0.34201775 0.36056606 0.34437922 0.35879744 0.32110394 0.35463618 0.35630593
0.35265335 0.33404507 0.31786589 0.36533048 0.33745658 0.34829867 0.35882662 0.33587373 0.38733648 0.34679925
0.34455421 0.32217376 0.31684900 0.34860528 0.34528150 0.34326666 0.35339036 0.31632613 0.39099875 0.34855293
0.34080499 0.32400623 0.31335705 0.34693229 0.34732043 0.32681319 0.35165384 0.34070280 0.35592693 0.35081058
0.35211403 0.31983738 0.31535696 0.34859874 0.33794105 0.32866267 0.35873195 0.31386764 0.35675679 0.35725450
0.35062895 0.31333751 0.31145495 0.33067614 0.33516298 0.39316398 0.34585347 0.31834995 0.36019945 0.34120194
0.34033514 0.31360651 0.31260432 0.33045062 0.32965201 0.33041890 0.34967584 0.33160156 0.34734816 0.37511453
0.33761110 0.31446264 0.30904517 0.36963024 0.32273239 0.40365853 0.38732372 0.30478417 0.35766615 0.34793633
0.33412832 0.31671963 0.30729363 0.33730657 0.32810578 0.33040037 0.34297715 0.31901629 0.35073184 0.33255548
0.34124553 0.32884773 0.30271713 0.33427871 0.35526720 0.32384830 0.34648729 0.46330189 0.34764518 0.33594650
0.33354130 0.33715460 0.30612995 0.32240094 0.35839825 0.32475754 0.34942867 0.30384673 0.34695553 0.33210517
0.33227035 0.31346479 0.30156690 0.33121169 0.32602389 0.31733833 0.34378226 0.30337871 0.34831533 0.34407743
0.33779861 0.30810347 0.33521520 0.32456299 0.33365951 0.32168364 0.34838441 0.30523982 0.33796162 0.33229462
0.33902138 0.31141322 0.30740697 0.33496056 0.32629874 0.34204254 0.34085294 0.31275697 0.48378840 0.33236764
0.37266557 0.34885473 0.32033306 0.32664545 0.32292080 0.31542538 0.35265733 0.34153071 0.36078571 0.32744491
0.32833558 0.31326533 0.29965293 0.32254346 0.32329573 0.31916460 0.33405890 0.31389911 0.34829852 0.33116877
0.33150051 0.33800660 0.29580056 0.33466057 0.31581161 0.32023546 0.36401807 0.32046386 0.34941658 0.34428792
0.32606547 0.32029337 0.30802225 0.33787492 0.33044953 0.32572788 0.34252810 0.30288016 0.33633721 0.34015713
0.32793469 0.30067405 0.30227439 0.31784495 0.32473930 0.31167416 0.34760531 0.31499499 0.34364755 0.32090392
0.32110061 0.39000363 0.29375753 0.35180134 0.32730982 0.31288070 0.33465695 0.29943170 0.36623465 0.32185657
0.36483713 0.31767564 0.28987998 0.31533400 0.32464926 0.33827247 0.33014493 0.30829340 0.34671771 0.35224315
0.32401044 0.31923085 0.29181427 0.31119836 0.33005578 0.31919908 0.33333557 0.29705411 0.34815464 0.32736964
