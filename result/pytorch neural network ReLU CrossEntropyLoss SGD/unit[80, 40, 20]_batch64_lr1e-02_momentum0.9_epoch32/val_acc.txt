# pytorch nn 3 hidden layer ReLU CrossEntropyLoss SGD:
#  unit=[80, 40, 20],batch=64,lr=1e-02,momentum0.9,epoch=32
0.70885092 0.58579195 0.31250000 0.48447204 0.30628881 0.34860247 0.34549689 0.27795032 0.68711179 0.44785991
0.82065219 0.82647514 0.82919252 0.81560558 0.82453418 0.82453418 0.81444097 0.81405282 0.81754661 0.81478602
0.82919252 0.83346272 0.84083849 0.84045029 0.83074534 0.82453418 0.81444097 0.83773291 0.82336956 0.82957196
0.83035713 0.84161490 0.84510869 0.83307451 0.83812112 0.83695650 0.82104039 0.83656830 0.82880437 0.82762647
0.82763976 0.82841617 0.76785713 0.84355593 0.83462733 0.83385092 0.82142860 0.83889753 0.82996893 0.83501947
0.83385092 0.84394407 0.84045029 0.84316772 0.83773291 0.84083849 0.82142860 0.84549689 0.83462733 0.83307391
0.84083849 0.84821427 0.84937888 0.84200311 0.83346272 0.83385092 0.82336956 0.85481364 0.83889753 0.83385211
0.83307451 0.85403728 0.84510869 0.84666151 0.84433228 0.84549689 0.80784160 0.85364908 0.84161490 0.84046692
0.82569873 0.84433228 0.84704971 0.84821427 0.84161490 0.84394407 0.82608694 0.85869563 0.83268636 0.84435797
0.84200311 0.85442549 0.85442549 0.84394407 0.84549689 0.84394407 0.83423913 0.81094718 0.83812112 0.84202337
0.84122670 0.84433228 0.85559005 0.84433228 0.84122670 0.85054350 0.82569873 0.84976709 0.82880437 0.84747082
0.84006214 0.84937888 0.85675466 0.85248446 0.83889753 0.83928573 0.83695650 0.86063665 0.84355593 0.84085602
0.84277952 0.84510869 0.85753107 0.82880437 0.84433228 0.83812112 0.83385092 0.84200311 0.82065219 0.84941632
0.84006214 0.85015529 0.85481364 0.84704971 0.83889753 0.84200311 0.83773291 0.86063665 0.81560558 0.84980547
0.84860247 0.85597825 0.85908383 0.84666151 0.84006214 0.84666151 0.83618015 0.84510869 0.84355593 0.85252917
0.84239131 0.85559005 0.85908383 0.84355593 0.84588510 0.85442549 0.83268636 0.86374223 0.84394407 0.85058367
0.83967394 0.86141306 0.86413044 0.85326087 0.84782606 0.81909937 0.84433228 0.86451864 0.83579195 0.85486382
0.84588510 0.85830748 0.86141306 0.85326087 0.84976709 0.84083849 0.84433228 0.84666151 0.84433228 0.84435797
0.85054350 0.86063665 0.86102486 0.82647514 0.85791928 0.80357140 0.81715840 0.86762422 0.84704971 0.85330737
0.85209626 0.85714287 0.86490685 0.85753107 0.85209626 0.84899068 0.84239131 0.85986024 0.84743786 0.86031127
0.84899068 0.84433228 0.86490685 0.85093170 0.84045029 0.85520184 0.83928573 0.77018636 0.84821427 0.86186773
0.85481364 0.84045029 0.86218941 0.85947204 0.83113354 0.85093170 0.83889753 0.86801243 0.85054350 0.86070037
0.85326087 0.86063665 0.87305903 0.85830748 0.85093170 0.85753107 0.84821427 0.86995339 0.84976709 0.85525292
0.85675466 0.86645961 0.85054350 0.85830748 0.85015529 0.85403728 0.84627330 0.86723602 0.85442549 0.85953307
0.85248446 0.86490685 0.87034160 0.85287267 0.85403728 0.84472048 0.85054350 0.86568326 0.75892860 0.86459142
0.84510869 0.84433228 0.85597825 0.85520184 0.85714287 0.85248446 0.84122670 0.84704971 0.84161490 0.86070037
0.86063665 0.86257762 0.86374223 0.86063665 0.85559005 0.85326087 0.85209626 0.86024845 0.84627330 0.87315178
0.86024845 0.85248446 0.87267083 0.85559005 0.86141306 0.85714287 0.83307451 0.85520184 0.84666151 0.86653697
0.86568326 0.85753107 0.86102486 0.85093170 0.85830748 0.84782606 0.84239131 0.86024845 0.85287267 0.85680932
0.86413044 0.86956519 0.86723602 0.86413044 0.85481364 0.86374223 0.83812112 0.85869563 0.85015529 0.86536968
0.86801243 0.80512422 0.87422359 0.85403728 0.85054350 0.86141306 0.85131985 0.86995339 0.85248446 0.87081712
0.84006214 0.86413044 0.87111801 0.86801243 0.85442549 0.85326087 0.85559005 0.86568326 0.85403728 0.86303502
0.86568326 0.86335403 0.87150621 0.86684781 0.85559005 0.86413044 0.85714287 0.86840063 0.85170805 0.87237352
