# pytorch nn 3 hidden layer ReLU CrossEntropyLoss SGD:
#  unit=[80, 40, 20],batch=64,lr=1e-02,momentum0.9,epoch=32
0.71479130 0.58086234 0.31874487 0.49182096 0.30394062 0.33821055 0.36112911 0.28054729 0.70050496 0.43417475
0.77051234 0.78350383 0.75855666 0.78397858 0.76951963 0.77072811 0.76740474 0.76295912 0.78527343 0.77833873
0.82597435 0.82696706 0.82597435 0.82731235 0.82329839 0.82467955 0.82968622 0.82347101 0.82718289 0.82593310
0.82450688 0.83279383 0.83063579 0.83124000 0.83188742 0.83041996 0.83206010 0.83223271 0.83521086 0.83236247
0.83171481 0.83788681 0.83413184 0.83408862 0.83499503 0.83348441 0.83581507 0.83322543 0.83836162 0.83370012
0.83741206 0.83987224 0.79248130 0.83913851 0.83844793 0.83693731 0.83853424 0.83879322 0.84146923 0.84030205
0.84401572 0.84565586 0.83456343 0.84207344 0.84159869 0.84034699 0.84155554 0.84237558 0.84336829 0.84448761
0.84401572 0.84846133 0.83939749 0.84595793 0.84095126 0.84159869 0.84617376 0.84492207 0.84884977 0.84578210
0.84755492 0.84992880 0.84267771 0.84565586 0.84647590 0.84431785 0.84729594 0.84854764 0.84979928 0.84854370
0.84785706 0.85031724 0.84738231 0.85027409 0.84790021 0.84790021 0.84746861 0.85113728 0.85221630 0.85492986
0.85471964 0.85644609 0.84764123 0.85204369 0.85247529 0.84841812 0.85070568 0.83136952 0.85441756 0.85423946
0.85722303 0.85640293 0.85286373 0.85407227 0.85433120 0.85221630 0.84997195 0.85307956 0.85653245 0.85592234
0.85519445 0.85912210 0.85389960 0.85791361 0.85553974 0.85105097 0.85497862 0.85610080 0.85825890 0.85618120
0.85964006 0.86149597 0.85670507 0.85998535 0.85709351 0.85640293 0.85765463 0.85113728 0.86054641 0.85825241
0.86283398 0.86421514 0.85955369 0.85933793 0.86033064 0.85346800 0.86020112 0.85847467 0.84474945 0.86049622
0.86481935 0.86857438 0.86054641 0.85985583 0.85489231 0.85890627 0.86158228 0.86033064 0.86140966 0.86377561
0.86434460 0.86818594 0.86235917 0.86494887 0.86253184 0.86071908 0.86058956 0.86248869 0.86210024 0.86463863
0.86568260 0.87051666 0.86395615 0.86792696 0.86628687 0.84673488 0.86559629 0.86434460 0.86443090 0.86675298
0.86680478 0.87232941 0.86468989 0.86943763 0.86615735 0.85989898 0.86650264 0.86041695 0.86775434 0.87055016
0.87068927 0.87604123 0.86663216 0.86602789 0.86680478 0.85018778 0.85057622 0.86866069 0.86702061 0.87089539
0.87159568 0.87500542 0.86909235 0.87043029 0.86999869 0.85873365 0.85938108 0.87133670 0.86943763 0.87162894
0.87263155 0.87746561 0.87086195 0.87271786 0.86197072 0.86546677 0.86607105 0.85247529 0.86909235 0.87206042
0.87517804 0.87332213 0.86361086 0.87353790 0.87129354 0.86533731 0.86930811 0.87060297 0.87194097 0.87633228
0.87612760 0.87845826 0.87207043 0.87694764 0.87323576 0.86576891 0.87215674 0.87241572 0.87345159 0.87288028
0.87699080 0.87966681 0.87349474 0.87824249 0.86516464 0.87090510 0.87301999 0.87880355 0.87530750 0.87646168
0.87712032 0.88217014 0.86922181 0.86784065 0.87384003 0.87146616 0.87504858 0.87703395 0.83706677 0.87784249
0.88307655 0.88303334 0.86430144 0.87802666 0.87548018 0.87263155 0.87841511 0.85631663 0.86555308 0.87469256
0.88536406 0.88122058 0.87306315 0.87863094 0.87647289 0.87457377 0.87798351 0.87535071 0.87310630 0.88250268
0.88411242 0.88441449 0.87388319 0.88277441 0.87914884 0.87539387 0.87798351 0.87863094 0.87750876 0.88125134
0.88627046 0.88147956 0.87824249 0.87837195 0.87232941 0.87504858 0.87120724 0.87970996 0.88018471 0.88345200
0.88704735 0.88937807 0.88109112 0.88402605 0.88096166 0.87897623 0.88048685 0.88014156 0.87953728 0.88189858
0.88890326 0.84595793 0.87794036 0.88475978 0.88204068 0.87772453 0.88208383 0.88450086 0.87970996 0.88638622
0.86490571 0.87405586 0.88087529 0.88868749 0.88277441 0.87763822 0.88299018 0.88566619 0.88165224 0.88690400
