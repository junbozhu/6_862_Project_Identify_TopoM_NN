# pytorch nn 3 hidden layer ReLU CrossEntropyLoss SGD:
#  unit=[80, 40, 20],batch=64,lr=1e-02,epoch=32
0.71479130 0.58086234 0.31874487 0.49182096 0.30394062 0.33821055 0.36112911 0.28054729 0.70050496 0.43417475
0.71720833 0.71418709 0.70508009 0.71505028 0.70201564 0.70948249 0.70710862 0.69877857 0.71759677 0.71339804
0.71725148 0.72083390 0.71444601 0.71820104 0.71647459 0.71746731 0.71634513 0.71517974 0.71846002 0.71741098
0.71725148 0.77733177 0.71444601 0.77746129 0.72299194 0.75575119 0.71915060 0.72294879 0.77331781 0.75305283
0.76023996 0.80590445 0.73710561 0.80793303 0.78402174 0.80111355 0.77948982 0.77426732 0.80650872 0.80366772
0.80521387 0.81363028 0.79735851 0.81634945 0.80724245 0.81341445 0.81160170 0.80184728 0.81583148 0.81402373
0.81457984 0.81820536 0.81065214 0.82062238 0.81544304 0.81846434 0.81850749 0.81233543 0.81898224 0.81980580
0.81919807 0.82053608 0.81673789 0.82273728 0.81837803 0.82083821 0.82161510 0.81725580 0.82217616 0.82114345
0.82049292 0.82394576 0.81876647 0.82472271 0.82161510 0.82407528 0.82398897 0.82010442 0.82511115 0.82153183
0.82342786 0.82511115 0.82118350 0.82558590 0.82355732 0.82519746 0.82537013 0.82269412 0.82683760 0.82459545
0.82614702 0.82770079 0.82213300 0.82826191 0.82467955 0.82748502 0.82783031 0.82403213 0.82800293 0.82489753
0.82739866 0.82890934 0.82558590 0.82865036 0.82644916 0.82890934 0.82860720 0.82554275 0.82955676 0.82632148
0.82899565 0.83011782 0.82770079 0.83098108 0.82795978 0.83011782 0.83011782 0.82783031 0.83024734 0.82817692
0.83041996 0.83171481 0.82938409 0.83197373 0.83029050 0.83093786 0.83158529 0.82951355 0.83085155 0.82998919
0.83206010 0.83244854 0.83063579 0.83279383 0.83102423 0.83296645 0.83300960 0.82990205 0.83227587 0.83132684
0.83257800 0.83357072 0.82977253 0.83352757 0.83102423 0.83257800 0.83357072 0.83162844 0.83335489 0.83149946
0.83305281 0.83387285 0.83162844 0.83348441 0.83145583 0.83300960 0.83456343 0.83167166 0.83443391 0.83296657
0.83469290 0.83611721 0.83313912 0.83521086 0.83348441 0.83408862 0.83477920 0.83244854 0.83512449 0.83279395
0.83508134 0.83676463 0.83400232 0.83534032 0.83339810 0.83370018 0.83460659 0.83395916 0.83525401 0.83361381
0.83382970 0.83676463 0.83482242 0.83706677 0.83559930 0.83512449 0.83564246 0.83555615 0.83624673 0.83464938
0.83577192 0.83749837 0.83477920 0.83780050 0.83482242 0.83568561 0.83616036 0.83572876 0.83628988 0.83533978
0.83529717 0.83840477 0.83568561 0.83862054 0.83551300 0.83572876 0.83719623 0.83439076 0.83654886 0.83723843
0.83525401 0.83948380 0.83676463 0.83909535 0.83672148 0.83719623 0.83810264 0.83525401 0.83762789 0.83779937
0.83736891 0.84108073 0.83663517 0.83982909 0.83628988 0.83741206 0.83788681 0.83508134 0.83836162 0.83853292
0.83892268 0.84177130 0.83680779 0.83931112 0.83745521 0.83814579 0.83922482 0.83663517 0.83969963 0.83892125
0.83926797 0.84181452 0.83654886 0.84043336 0.83732575 0.83840477 0.84151238 0.83849108 0.83978593 0.83999997
0.84021753 0.84315246 0.83335489 0.84095126 0.83762789 0.83823210 0.84095126 0.83728260 0.84073550 0.84038836
0.84056282 0.84297985 0.83844793 0.84155554 0.83896583 0.84060597 0.84172815 0.84026068 0.84086496 0.84090614
0.84168500 0.84323883 0.83870691 0.84211659 0.83913851 0.84034699 0.84371358 0.84034699 0.84138286 0.84302050
0.84224612 0.84518105 0.84004492 0.84220296 0.83969963 0.84069228 0.84371358 0.84241873 0.84246188 0.84392667
0.84250510 0.84569901 0.84073550 0.84341145 0.84082180 0.84151238 0.84565586 0.84099442 0.84341145 0.84509170
0.84354097 0.84548318 0.84064913 0.84470630 0.84146923 0.84259140 0.84544003 0.84203029 0.84392941 0.84509170
0.84401572 0.84626007 0.84159869 0.84513789 0.84211659 0.84285039 0.84699380 0.84345460 0.84444731 0.84578210
