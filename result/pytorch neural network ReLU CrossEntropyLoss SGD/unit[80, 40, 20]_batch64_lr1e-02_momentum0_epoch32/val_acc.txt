# pytorch nn 3 hidden layer ReLU CrossEntropyLoss SGD:
#  unit=[80, 40, 20],batch=64,lr=1e-02,epoch=32
0.70885092 0.58579195 0.31250000 0.48447204 0.30628881 0.34860247 0.34549689 0.27795032 0.68711179 0.44785991
0.71118015 0.71700311 0.73641306 0.71234471 0.71816772 0.70885092 0.71933228 0.72981364 0.70458072 0.70972764
0.71118015 0.72981364 0.73641306 0.71583849 0.71816772 0.70962733 0.71933228 0.72981364 0.70962733 0.70972764
0.71118015 0.79347825 0.73641306 0.80124223 0.76475155 0.79425466 0.72826087 0.75815219 0.79192549 0.79260701
0.80007762 0.80745339 0.79619563 0.82026398 0.80318326 0.81366462 0.80124223 0.79192549 0.80628884 0.80583656
0.81133538 0.81366462 0.80784160 0.82259315 0.81909937 0.81715840 0.81094718 0.80473602 0.81172359 0.81050581
0.81638199 0.81832296 0.82181674 0.82569873 0.82414597 0.81327641 0.81560558 0.80978262 0.80900621 0.80856031
0.81948757 0.82065219 0.82531059 0.83190995 0.82220495 0.82336956 0.81715840 0.81599379 0.81909937 0.81361866
0.81871116 0.82841617 0.82492238 0.83035713 0.82298136 0.82298136 0.81677020 0.81793481 0.82414597 0.81673151
0.82647514 0.83152175 0.83229816 0.83190995 0.82763976 0.82065219 0.81948757 0.82686335 0.82414597 0.82178986
0.82569873 0.82065219 0.83307451 0.83035713 0.82919252 0.82453418 0.81094718 0.82492238 0.81793481 0.82062256
0.82608694 0.83307451 0.83307451 0.83385092 0.83074534 0.82763976 0.81250000 0.82802796 0.82919252 0.82412452
0.82725155 0.83618015 0.83113354 0.83734471 0.82996893 0.83035713 0.81832296 0.81987578 0.82375777 0.82607001
0.82763976 0.83656830 0.83385092 0.83889753 0.83152175 0.82802796 0.81909937 0.83035713 0.81250000 0.82762647
0.82531059 0.84006214 0.82802796 0.83695650 0.83074534 0.83462733 0.81521738 0.83501554 0.82919252 0.82256812
0.82919252 0.83618015 0.83850932 0.83346272 0.79503107 0.83113354 0.81948757 0.83540374 0.82880437 0.82801557
0.82492238 0.84083849 0.84161490 0.84006214 0.82880437 0.82104039 0.81560558 0.83656830 0.82647514 0.83112842
0.83035713 0.84083849 0.83734471 0.83967394 0.83035713 0.83423913 0.81987578 0.83152175 0.83035713 0.83035022
0.82919252 0.84239131 0.84472048 0.83385092 0.83152175 0.80395961 0.81715840 0.83695650 0.82569873 0.83035022
0.83268636 0.84122670 0.83928573 0.83850932 0.83268636 0.82414597 0.82065219 0.83889753 0.81482917 0.83073932
0.82958072 0.84161490 0.84083849 0.84083849 0.82104039 0.83462733 0.81677020 0.80551243 0.82996893 0.83229572
0.83035713 0.82841617 0.84083849 0.84083849 0.82686335 0.83501554 0.81987578 0.83889753 0.82802796 0.83190662
0.83074534 0.84510869 0.84588510 0.84083849 0.83385092 0.83540374 0.80667704 0.82880437 0.82841617 0.83112842
0.83074534 0.84510869 0.81521738 0.84006214 0.82841617 0.83812112 0.81987578 0.84316772 0.82569873 0.83307391
0.83074534 0.84549689 0.83501554 0.83462733 0.83229816 0.83501554 0.81987578 0.84472048 0.79736024 0.83424127
0.83307451 0.84277952 0.81987578 0.83889753 0.83035713 0.83385092 0.82414597 0.83462733 0.80861801 0.83852142
0.83268636 0.83462733 0.84316772 0.83850932 0.83462733 0.83385092 0.82686335 0.84472048 0.82880437 0.83501947
0.83423913 0.79541928 0.84083849 0.84200311 0.84083849 0.83695650 0.81599379 0.84200311 0.82569873 0.83501947
0.83074534 0.84510869 0.84860247 0.82802796 0.82647514 0.83773291 0.81909937 0.84472048 0.83035713 0.83540857
0.83462733 0.84627330 0.84666151 0.84316772 0.83579195 0.83773291 0.82259315 0.83889753 0.83035713 0.84085602
0.83152175 0.80201864 0.84821427 0.84083849 0.84083849 0.84045029 0.82531059 0.84666151 0.83229816 0.83968872
0.82725155 0.84937888 0.84860247 0.84472048 0.83695650 0.83035713 0.83074534 0.84433228 0.83540374 0.84435797
0.83307451 0.84704971 0.84937888 0.83540374 0.83385092 0.83889753 0.83035713 0.84355593 0.83152175 0.83813232
