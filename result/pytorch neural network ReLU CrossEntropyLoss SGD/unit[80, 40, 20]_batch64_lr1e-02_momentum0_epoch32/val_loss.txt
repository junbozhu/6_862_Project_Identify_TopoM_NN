# pytorch nn 3 hidden layer ReLU CrossEntropyLoss SGD:
#  unit=[80, 40, 20],batch=64,lr=1e-02,epoch=32
0.68074400 0.68597831 0.70245087 0.69407235 0.71670264 0.70376061 0.70665545 0.71869313 0.67612317 0.69727624
0.57331286 0.53223754 0.56935154 0.54313242 0.56945687 0.54561911 0.58767808 0.57002484 0.54610995 0.56385104
0.52759500 0.46921827 0.53702298 0.46848563 0.51538763 0.48226806 0.54560205 0.52731056 0.47384160 0.49338715
0.46704696 0.42150642 0.48406787 0.41858337 0.45110311 0.42560340 0.47759233 0.46579036 0.43533700 0.43680989
0.42740413 0.40443821 0.43378406 0.39771793 0.40895555 0.39818680 0.42574005 0.41148301 0.41982268 0.41682883
0.40907502 0.39031406 0.39374943 0.38970081 0.39340971 0.38611519 0.41026801 0.38937218 0.41177492 0.40901939
0.39863144 0.38293751 0.38160507 0.38426441 0.39156854 0.38802204 0.40517181 0.38053639 0.40962437 0.40742808
0.39255787 0.37770792 0.37373481 0.38110352 0.38050240 0.37494847 0.40051281 0.37428342 0.40290498 0.40061819
0.39395710 0.37461554 0.36763573 0.37694307 0.37703930 0.37315550 0.39781440 0.36897134 0.39849681 0.39802576
0.38492677 0.36985773 0.36544045 0.37421783 0.37395987 0.37089183 0.39556220 0.38650374 0.39574431 0.39344860
0.38253559 0.37135803 0.36022004 0.37477130 0.37139153 0.36788142 0.39738280 0.36065361 0.39643988 0.38996704
0.38010084 0.36565537 0.35739258 0.36997434 0.36858810 0.37265808 0.39576372 0.35784844 0.39147332 0.38778102
0.37838067 0.36175796 0.35639084 0.36894742 0.37500725 0.36479903 0.39024624 0.36214895 0.39229972 0.38523462
0.37601582 0.35947388 0.35581734 0.36684467 0.36558383 0.36441117 0.38885420 0.35332051 0.39868547 0.38329106
0.37539422 0.35783738 0.35496211 0.36765642 0.37827459 0.36063694 0.38967241 0.35443918 0.38628546 0.38871910
0.37326670 0.35691572 0.34925360 0.36817855 0.44188040 0.36186352 0.38648968 0.36225158 0.38561868 0.38259732
0.37588101 0.35419839 0.34725071 0.36335936 0.36123357 0.37335848 0.38873816 0.34976379 0.38430395 0.37740138
0.37069053 0.35318789 0.35487301 0.36290419 0.36036025 0.35734428 0.38458901 0.35449369 0.38200892 0.38228629
0.36972334 0.35252021 0.34535809 0.36699727 0.36790374 0.41066060 0.39976545 0.34466442 0.38140965 0.37433394
0.37059025 0.34975636 0.34414259 0.36298359 0.35864906 0.36277903 0.38600711 0.34707649 0.39284893 0.37314400
0.36952292 0.34958772 0.34660834 0.36037093 0.37645895 0.35455405 0.38661953 0.43537268 0.38019525 0.37247380
0.36677774 0.36110334 0.34338762 0.35943187 0.36958649 0.35360885 0.38175689 0.34359768 0.37831496 0.37159851
0.36606181 0.34700072 0.33933372 0.35870198 0.35538458 0.35296082 0.40765365 0.35527389 0.38150883 0.36886729
0.36626595 0.34593852 0.41793447 0.35737885 0.36307320 0.35286735 0.38148841 0.33817361 0.38339706 0.36887780
0.36677383 0.34538803 0.35717729 0.36337808 0.36141787 0.35306073 0.38182647 0.33684974 0.42549927 0.36814325
0.36441102 0.35090269 0.41972583 0.35679780 0.36018546 0.35707553 0.37784190 0.36468777 0.40905647 0.36993045
0.36316987 0.35432484 0.34020249 0.36308216 0.35475903 0.35161646 0.37755345 0.33586924 0.37430553 0.36539990
0.36383729 0.42503551 0.34431270 0.35572189 0.35293744 0.34980952 0.38664614 0.33558337 0.37660935 0.36527515
0.36242362 0.34710977 0.33702788 0.37369243 0.37427939 0.34873085 0.38615505 0.33574018 0.37377430 0.36431363
0.36250645 0.34445732 0.33956934 0.35421945 0.35124263 0.35118742 0.37682903 0.34329359 0.37302560 0.36545100
0.36125729 0.40962807 0.33371717 0.35889297 0.35203332 0.34809455 0.37744994 0.33279782 0.37667793 0.36254636
0.36558807 0.34012366 0.33410537 0.35423047 0.35029556 0.35961585 0.37472073 0.33874568 0.37151030 0.36665464
0.36058868 0.34023820 0.33698830 0.36241217 0.35643227 0.34672565 0.37475222 0.33735527 0.37391453 0.36333751
